View(menshot)
plot(womenshot$Year,womenshot$Record,main='Womens Shotput World Records',xlab='Year',ylab='World Record Distance (m)',pch=16)
linFit(menshot$Year, menshot$Record)
linFit(womenshot$Year,womenshot$Record)
plot(menshot$Year,menshot$Record,main='Mens Shotput World Records',xlab='Year',ylab='World Record Distance (m)',pch=16)
linFit(menshot$Year, menshot$Record)
linFit(menshot$Year, menshot$Record)
linFit(womenshot$Year,womenshot$Record)
mensmile <- WR[WR$Event == 'Mens Mile',]
View(mensmile)
womensmile <- WR[WR$Event == 'Womens Mile',]
View(womensmile)
View(mensmile)
View(mensmile)
View(mensmile)
plot(mensmile$Year,mensmile$Record,main='Mens Mile World Records',xlab='Year',ylab='World Record Time (s)',pch=16)
plot(womensmile$Year,womensmile$Record,main='Womens Mile World Records',xlab='Year',ylab='World Record Time (s)',pch=16)
linFit(mensmile$Year, mensmile$Record)
linFit(womenmile$Year,womenmile$Record)
linFit(womensmile$Year,womensmile$Record)
plot(mensmile$Year,mensmile$Record,main='Mens Mile World Records',xlab='Year',ylab='World Record Time (s)',pch=16)
plot(womensmile$Year,womensmile$Record,main='Womens Mile World Records',xlab='Year',ylab='World Record Time (s)',pch=16)
linFit(mensmile$Year, mensmile$Record)
linFit(womensmile$Year,womensmile$Record)
help(inv)
inverse
0.5^-1
-0.39347^-1
-0.97288^-1
cor(mensmile$Year, mensmile$Record)
r = cor(mensmile$Year, mensmile$Record)
r^2
View(WR)
table(WR$Event)
menspole <- WR[WR$Event == 'Mens Polevault',]
View(menspole)
menspole <- WR[WR$Event == 'Mens Polevault' & WR$Year >= 1970,]
View(menspole)
which(menspole$Record > 6.00)
plot(menspole$Year, menspole$Record)
linFit(menspole$Year, menspole$Record)
C = c(140, 280, 420, 560)
h = c(0,2,4,6)
linFit(h,C)
4 * 175
700 / 70
560 / 4
175 * 4
700 - 140
560 / 4
560 / 70
y = 70*8 + 140
y
y = linFit(h,C)
y
2.84 + .04*970
2.84 + .04*9.70
3.71 - 2.84
2.84 + .04*14.5
2.91 - 3.42
library(SDSFoundations)
world <- WorldBankData
head(world)
which(world$IncomeGroup == 'Low Income')
which(world$IncomeGroup == 'Low income')
which(world$IncomeGroup == 'Low income')[0]
a = which(world$IncomeGroup == 'Low income')
a
a[0]
a[1]
world[54,]
world[54:55,]
View(world)
View(world)
View(world)
View(world)
which(world$Country == 'Aruba' & year == '1970')$rural.population
which(world$Country == 'Aruba' & world$year == '1970')$rural.population
which(world$Country == 'Aruba' & world$year == '1970')
world$rural.population[11]
which(world$Country == 'Australia' & world$mobile.users > 0)
world$year[611]
a = which(world$Country == 'Australia' & world$mobile.users > 0)
world$year[a]
library(SDSFoundations)
# Subset data for just the United States and name the new data frame "us"
us <- world[world$Country.Code == "USA",]
# Select the years from 1990 and name the new data frame "us_select"
us_select <- us[us$year >= 1990, ]
# Make the number of users more interpretable (into millions)
us_select$internet.mil <- us_select$internet.users / 1000000
# Create a new variable that is "years since 1990"
us_select$time <- us_select$year - 1990
# Select the first 10 years (from 1990 to 1999) and name the new data frame "us_select_10"
us_select_10 <- us_select[us_select$time < 10,]
# Use a function to fit an exponential and logistic model for 1990-1999
expFit(us_select_10$time, us_select_10$internet.mil)
logisticFit(us_select_10$time, us_select_10$internet.mil)
# Based on the prior model parameters, predict the number of internet users in 2006
e <- expFitPred(us_select_10$time, us_select_10$internet.mil, 16)
l <- logisticFitPred(us_select_10$time, us_select_10$internet.mil, 16)
# Show how many internet users the US actually had in 2006
us_select[us_select$time == 16, c("Country", "year", "internet.mil")]
# Calculate the residuals for each model
us_select$internet.mil[us_select$time == 16] - e
us_select$internet.mil[us_select$time == 16] - l
# Look at the model fits for all available data (1990 to 2012)
expFit(us_select$time, us_select$internet.mil)
logisticFit(us_select$time, us_select$internet.mil)
# Which model fits the best?
tripleFit(us_select$time, us_select$internet.mil)
# How many internet users would the US have had in 2012 if you had used the original exponential model?
expFitPred(us_select_10$time, us_select_10$internet.mil, 22)
expFitPred(us_select_10$time, us_select_10$internet.mil, 22)
expFitPred(us_select_10$time, us_select_10$internet.mil, 22)
ee <- expFitPred(us_select_10$time, us_select_10$internet.mil, 22)
View(world)
inet_users_prop <- world$internet.users / world$population
head inet_users_prop
head(inet_users_prop)
inet_users_prop
world_1990_up <- world[world$year >= 1990,]
world$internet.users_prop = world$internet.users / world$population
View(world)
View(world_1990_up)
world_1990_up <- world[world$year >= 1990,]
View(world_1990_up)
world_1990_up$years_since_1990 <- world_1990_up$year - 1990
View(world_1990_up)
denmark <- world_1990_up[world_1990_up$Country = 'Denmark',]
denmark <- world_1990_up[world_1990_up$Country == 'Denmark',]
belarus <- world_1990_up[world_1990_up$Country == 'Belarus',]
expFit(denmark$years_since_1990, denmark$internet.users_prop)
logisticFit(denmark$years_since_1990, denmark$internet.users_prop)
expFit(belarus$years_since_1990, belarus$internet.users_prop)
logisticFit(belarus$years_since_1990, belarus$internet.users_prop)
expFit(denmark$years_since_1990, denmark$internet.users_prop)
(denmark$years_since_1990, denmark$internet.users_prop)
logisticFit(denmark$years_since_1990, denmark$internet.users_prop)
expFit(belarus$years_since_1990, belarus$internet.users_prop)
logisticFit(belarus$years_since_1990, belarus$internet.users_prop)
logisticFit(denmark$years_since_1990, denmark$internet.users_prop)
ln(1)
log(1)
log((0.1 * 308.8345)/(0.89668-0.1))/log(1.73124)
logisticFitPred(denmark$years_since_1990, denmark$internet.users_prop)
logisticFitPred(denmark$years_since_1990, denmark$internet.users_prop, 7)
logisticFitPred(denmark$years_since_1990, denmark$internet.users_prop, 6)
logisticFitPred(denmark$years_since_1990, denmark$internet.users_prop, 8)
logisticFitPred(denmark$years_since_1990, denmark$internet.users_prop, 7)
logisticFit(belarus$years_since_1990, belarus$internet.users_prop)
log((0.1 * 422.4322)/(0.8987-0.1))/log(1.31884)
logisticFitPred(belarus$years_since_1990, belarus$internet.users_prop, 14)
logisticFitPred(belarus$years_since_1990, belarus$internet.users_prop, 15)
logisticFit(denmark$years_since_1990, denmark$internet.users_prop)
logisticFitPred(denmark$years_since_1990, denmark$internet.users_prop, 7)
logisticFitPred(denmark$years_since_1990, denmark$internet.users_prop, 6)
logisticFitPred(denmark$years_since_1990, denmark$internet.users_prop, 7)
logisticFitPred(belarus$years_since_1990, belarus$internet.users_prop, 14)
logisticFitPred(belarus$years_since_1990, belarus$internet.users_prop, 15)
logisticFitPred(denmark$years_since_1990, denmark$internet.users_prop, 7)
logisticFitPred(denmark$years_since_1990, denmark$internet.users_prop, 14)
logisticFitPred(denmark$years_since_1990, denmark$internet.users_prop, 15)
logisticFitPred(belarus$years_since_1990, belarus$internet.users_prop, 15)
logisticFitPred(belarus$years_since_1990, belarus$internet.users_prop, 30)
logisticFitPred(belarus$years_since_1990, belarus$internet.users_prop, 29)
logisticFitPred(belarus$years_since_1990, belarus$internet.users_prop, 30)
world$internet.users_prop = world$internet.users / world$population
world_1990_up <- world[world$year >= 1990,]
world_1990_up$years_since_1990 <- world_1990_up$year - 1990
denmark <- world_1990_up[world_1990_up$Country == 'Denmark',]
belarus <- world_1990_up[world_1990_up$Country == 'Belarus',]
# denmark
expFit(denmark$years_since_1990, denmark$internet.users_prop)
logisticFit(denmark$years_since_1990, denmark$internet.users_prop)
logisticFitPred(denmark$years_since_1990, denmark$internet.users_prop, 7)
logisticFitPred(denmark$years_since_1990, denmark$internet.users_prop, 15)
# belarus
expFit(belarus$years_since_1990, belarus$internet.users_prop)
logisticFit(belarus$years_since_1990, belarus$internet.users_prop)
logisticFitPred(belarus$years_since_1990, belarus$internet.users_prop, 30)
logisticFit(belarus$years_since_1990, belarus$internet.users_prop)
logisticFitPred(belarus$years_since_1990, belarus$internet.users_prop, 15)
logisticFitPred(belarus$years_since_1990, belarus$internet.users_prop, 14)
logisticFitPred(belarus$years_since_1990, belarus$internet.users_prop, 30)
logisticFitPred(belarus$years_since_1990, belarus$internet.users_prop, 29)
29 - 14
logisticFitPred(denmark$years_since_1990, denmark$internet.users_prop, 7)
logisticFitPred(denmark$years_since_1990, denmark$internet.users_prop, 6)
logisticFitPred(denmark$years_since_1990, denmark$internet.users_prop, 7)
logisticFitPred(denmark$years_since_1990, denmark$internet.users_prop, 14)
logisticFitPred(denmark$years_since_1990, denmark$internet.users_prop, 15)
logisticFitPred(denmark$years_since_1990, denmark$internet.users_prop, 14)
cls
brazil <- world[which(world$Country == 'Brazil' & world$year >= 1995),]
View(brazil)
brazil$year <- brazil$year - 1995
view(brazil)
View(brazil)
brazil$mobile.users <- brazil$mobile.users / 1000000
View(brazil)
brazil$mobile.users[brazil$year == 5]
which(brazil$mobile.users >= 100)
brazil$year <- brazil$year + 1995
View(brazil)
brazil[13,]
brazil$time <- brazil$year - 1995
tripleFit(brazil$time, brazil$mobile.users)
logisticFitPred(brazil$time, brazil$mobile.users)
logisticFitPred(brazil$time, brazil$mobile.users, 2025 - 1995)
367 - 257
367 / 257
257 * 1.42
257 * 1.428
257 * 1.428016
257 * 1.49
257 * 1.43
2^2
2^3
76.64*1.46^14
3273.31 / (1 + 43.59 * 1.57 ^ 14)
3273.31 / (1 + 43.59 * (1.57 ^ 14))
3273.31 / (1 + 43.59 * (1.57 ^ -14))
4379 - 15325
4379 - 3034
(45 - 25) / (3-1)
45 / 25 - 1
sqrt(4)
sqrt(45/25)
25 / 1.34
45 / 1.34 ^ 3
45 / (1.34 ^ 3)
25 / 1.34
2012 - 1996
2012 - 1995
10 * 17 + 15
19 * 1.34 ^ 17
1.34 ^ 17
19 * 1.34 ^ 17
19 * 1.34 ^ 7
log(152.10) / log(2.17)
2000 / (1 + 152.10 * 2.17 ^ -9)
`2015.02.15_Personal.Expense` <- read.csv("~/Dropbox/ExpenseManager/CSV/2015-02-15_Personal Expense.csv")
View(`2015.02.15_Personal.Expense`)
`2015.02.15_Personal_Expense` <- read.csv("~/Dropbox/ExpenseManager/analysis/2015-02-15_Personal_Expense.csv")
View(`2015.02.15_Personal_Expense`)
`2015.02.15_Personal_Expense` <- read.csv("~/Dropbox/ExpenseManager/analysis/2015-02-15_Personal_Expense.csv")
View(`2015.02.15_Personal_Expense`)
View(`2015.02.15_Personal_Expense`)
View(`2015.02.15_Personal_Expense`)
save.image("~/Dropbox/ExpenseManager/analysis/2015-02-15_Personal_Expense.RData")
View(`2015.02.15_Personal_Expense`)
head(data)
data <- 2015.02.15_Personal_expense
View(`2015.02.15_Personal_Expense`)
View(`2015.02.15_Personal_Expense`)
head(data)
head(data)
data
data[0]
View(`2015.02.15_Personal_Expense`)
View(`2015.02.15_Personal_Expense`)
View(`2015.02.15_Personal_Expense`)
View(`2015.02.15_Personal_Expense`)
load("~/Dropbox/ExpenseManager/analysis/2015-02-15_Personal_Expense.RData")
View(`2015.02.15_Personal_Expense`)
head(`2015.02.15_Personal_Expense`)
tabe(`2015.02.15_Personal_Expense`)
table(`2015.02.15_Personal_Expense`)
data <- `2015.02.15_Personal_Expense`
View(`2015.02.15_Personal_Expense`)
View(data)
type
help(type)
typeof(data[0,[])
typeof(data[0,0)
typeof(data[0,0])
data$Date
data$Date[0]
as.Date(data$Date[0])
typeof(data$Date[0,0])
typeof(data$Date[0])
as.String(data$Date[0])
as.character(data$Date[0])
monthly = c(36518.40, 31904.14, 31932.83, 28319.32, 32883.77)
sum(monthly)
average(monthly)
mean(monthly)
monthly_expenses <- monthly
m <- mean(monthly) + 20000
m
annual <- m * 12
nestegg <- annual * 30
2^2
2^3
r <- 1.05
P <- nestegg
P * r^30
monthly <- m
P
81391723 / 35
T <- P * r^30
T
annual_T <- T / 35
annual_T
monthly_T <- annual_T / 12
monthly_T
T
annual_T
monthly_T
115000 * 1.03^30
115000 * 12
1380000 * 1.03^30
1380000 * 1.03^15
1380000 * 1.03^16
1380000 * 1.03^17
1380000 * 1.03^18
mean(monthly_expenses)
1500000 * 1.15^35
install.packages("ggplot2")
update.packages(checkBuilt=TRUE)
y
install.packages("ggplot2")
install.packages("ggplot2")
library(caret)
install.packages("e1071")
library(e1071)
numFolds = trainControl( method = "cv", number = 10 )
cpGrid = expand.grid( .cp = seq(0.01,0.5,0.01))
train(Reverse ~ Circuit + Issue + Petitioner + Respondent + LowerCourt + Unconst, data = Train, method = "rpart", trControl = numFolds, tuneGrid = cpGrid )
install.packages("class")
install.packages("class")
train(Reverse ~ Circuit + Issue + Petitioner + Respondent + LowerCourt + Unconst, data = Train, method = "rpart", trControl = numFolds, tuneGrid = cpGrid )
library(caTools)
library(rpart)
library(rpart.plot)
library(ROCR)
library(randomForest)
library(caret)
library(e1071)
numFolds = trainControl( method = "cv", number = 10 )
cpGrid = expand.grid( .cp = seq(0.01,0.5,0.01))
train(Reverse ~ Circuit + Issue + Petitioner + Respondent + LowerCourt + Unconst, data = Train, method = "rpart", trControl = numFolds, tuneGrid = cpGrid )
train
install.packages("caret")
install.packages("caret")
install.packages("caret")
install.packages("caret")
library(caret)
setwd("~/Code/AnalyticsEdge/Unit4")
stevens = read.csv("stevens.csv")
library(caTools)
set.seed(3000)
spl = sample.split(stevens$Reverse, SplitRatio = 0.7)
Train = subset(stevens, spl==TRUE)
Test = subset(stevens, spl==FALSE)
install.packages("caret")
library(caret)
library(e1071)
numFolds = trainControl( method = "cv", number = 10 )
cpGrid = expand.grid( .cp = seq(0.01,0.5,0.01))
train(Reverse ~ Circuit + Issue + Petitioner + Respondent + LowerCourt + Unconst, data=Train, method="rpart", trControl=numFolds, tuneGrid=cpGrid )
stevens = read.csv("stevens.csv")
library(caTools)
set.seed(3000)
spl = sample.split(stevens$Reverse, SplitRatio = 0.7)
Train = subset(stevens, spl==TRUE)
Test = subset(stevens, spl==FALSE)
library(rpart)
library(rpart.plot)
library(ROCR)
library(randomForest)
Train$Reverse = as.factor(Train$Reverse)
Test$Reverse = as.factor(Test$Reverse)
numFolds = trainControl( method = "cv", number = 10 )
cpGrid = expand.grid( .cp = seq(0.01,0.5,0.01))
train(Reverse ~ Circuit + Issue + Petitioner + Respondent + LowerCourt + Unconst, data=Train, method="rpart", trControl=numFolds, tuneGrid=cpGrid )
StevensTreeCV = rpart(Reverse ~ Circuit + Issue + Petitioner + Respondent + LowerCourt + Unconst, data = Train, method="class", cp = 0.18)
PredictCV = predict(StevensTreeCV, newdata = Test, type = "class")
table(Test$Reverse, PredictCV)
(59+64)/(59+18+29+64)
(59+64)/(59+18+29+64)
prp(StevensTreeCV)
setwd("~/Code/AnalyticsEdge/Unit4")
Claims = read.csv("ClaimsData.csv")
str(Claims)
table(Claims$bucket2009)/nrow(Claims)
library(caTools)
set.seed(88)
spl = sample.split(Claims$bucket2009, SplitRatio = 0.6)
ClaimsTrain = subset(Claims, spl==TRUE)
ClaimsTest = subset(Claims, spl==FALSE)
summary(ClaimsTrain)
str(ClaimsTrain)
which(ClaimsTrain$diabetes == 1)
nrow(which(ClaimsTrain$diabetes == 1))
str(ClaimsTrain$diabetes == 1)
nrow(ClaimsTrain)
str(which(ClaimsTrain$diabetes == 1))
104672 / 274803
table(ClaimsTest$bucket2009, ClaimsTest$bucket2008)
(110138 + 10721 + 2774 + 1539 + 104)/nrow(ClaimsTest)
PenaltyMatrix = matrix(c(0,1,2,3,4,2,0,1,2,3,4,2,0,1,2,6,4,2,0,1,8,6,4,2,0), byrow=TRUE, nrow=5)
PenaltyMatrix
as.matrix(table(ClaimsTest$bucket2009, ClaimsTest$bucket2008))*PenaltyMatrix
sum(as.matrix(table(ClaimsTest$bucket2009, ClaimsTest$bucket2008))*PenaltyMatrix)/nrow(ClaimsTest)
sum(as.matrix(table(ClaimsTest$bucket2009, ClaimsTest$bucket2008))*PenaltyMatrix)/nrow(ClaimsTest)
str(ClaimsTrain)
table(ClaimsTrain$bucket2008)
table(ClaimsTest$bucket2009, ClaimsTest$bucket2008)
bucket <- c(1) * 2
bucket
bucket <- numeric(nrow(ClaimsTrain))
bucket
bucket <- numeric(nrow(ClaimsTrain)) * 1
bucket
bucket <- numeric(nrow(ClaimsTrain)) + 1
bucket
nrow(ClaimsTrain)
str(bucket)
table(ClaimsTest$bucket2009, bucket)
str(ClaimsTest$bucket2009)
bucket <- numeric(nrow(ClaimsTest)) + 1
table(ClaimsTest$bucket2009, bucket)
table(ClaimsTest$bucket2009, ClaimsTest$bucket2008)
122978 / nrow(ClaimsTest)
as.matrix(table(ClaimsTest$bucket2009, bucket))*PenaltyMatrix
table(ClaimsTest$bucket2009, ClaimsTest$bucket2008)
table(ClaimsTest$bucket2009, bucket)
mat = matrix(c(122978,0,0,0,0,34840,0,0,0,0,16390,0,0,0,0,7937,0,0,0,0,1057,0,0,0,0), byrow=TRUE, nrow=5)
mat
mat * PenaltyMatrix
sum(mat * PenaltyMatrix) / nrow(ClaimsTest)
library(rpart)
library(rpart.plot)
ClaimsTree = rpart(bucket2009 ~ age + alzheimers + arthritis + cancer + copd + depression + diabetes + heart.failure + ihd + kidney + osteoporosis + stroke + bucket2008 + reimbursement2008, data=ClaimsTrain, method="class", cp=0.00005)
prp(ClaimsTree)
PredictTest = predict(ClaimsTree, newdata = ClaimsTest, type = "class")
table(ClaimsTest$bucket2009, PredictTest)
(114141 + 16102 + 118 + 201 + 0)/nrow(ClaimsTest)
ClaimsTree = rpart(bucket2009 ~ age + alzheimers + arthritis + cancer + copd + depression + diabetes + heart.failure + ihd + kidney + osteoporosis + stroke + bucket2008 + reimbursement2008, data=ClaimsTrain, method="class", cp=0.00005, parms=list(loss=PenaltyMatrix))
PredictTest = predict(ClaimsTree, newdata = ClaimsTest, type = "class")
table(ClaimsTest$bucket2009, PredictTest)
(94310 + 18942 + 4692 + 636 + 2)/nrow(ClaimsTest)
sum(as.matrix(table(ClaimsTest$bucket2009, PredictTest))*PenaltyMatrix)/nrow(ClaimsTest)
sum(as.matrix(table(ClaimsTest$bucket2009, PredictTest))*PenaltyMatrix)/nrow(ClaimsTest)
sum(as.matrix(table(ClaimsTest$bucket2009, PredictTest))*PenaltyMatrix)/nrow(ClaimsTest)
PenaltyMatrix
boston = read.csv("boston.csv")
str(boston)
plot(boston$LON, boston$LAT)
points(boston$LON[boston$CHAS==1], boston$LAT[boston$CHAS==1], col="blue", pch=19)
points(boston$LON[boston$TRACT==3531],boston$LAT[boston$TRACT==3531],col="red", pch=20)
summary(boston$NOX)
points(boston$LON[boston$NOX>=0.55], boston$LAT[boston$NOX>=0.55], col="green", pch=20)
plot(boston$LON, boston$LAT)
summary(boston$MEDV)
points(boston$LON[boston$MEDV>=21.2], boston$LAT[boston$MEDV>=21.2], col="red", pch=20)
plot(boston$LAT, boston$MEDV)
plot(boston$LON, boston$MEDV)
latlonlm = lm(MEDV ~ LAT + LON, data=boston)
summary(latlonlm)
plot(boston$LON, boston$LAT)
points(boston$LON[boston$MEDV>=21.2], boston$LAT[boston$MEDV>=21.2], col="red", pch=20)
latlonlm$fitted.values
latlonlm$fitted.values
points(boston$LON[latlonlm$fitted.values >= 21.2], boston$LAT[latlonlm$fitted.values >= 21.2], col="blue", pch="$")
library(rpart)
library(rpart.plot)
latlontree = rpart(MEDV ~ LAT + LON, data=boston)
prp(latlontree)
plot(boston$LON, boston$LAT)
points(boston$LON[boston$MEDV>=21.2], boston$LAT[boston$MEDV>=21.2], col="red", pch=20)
fittedvalues = predict(latlontree)
points(boston$LON[fittedvalues>21.2], boston$LAT[fittedvalues>=21.2], col="blue", pch="$")
latlontree = rpart(MEDV ~ LAT + LON, data=boston, minbucket=50)
plot(latlontree)
text(latlontree)
plot(boston$LON,boston$LAT)
abline(v=-71.07)
abline(h=42.21)
abline(h=42.17)
points(boston$LON[boston$MEDV>=21.2], boston$LAT[boston$MEDV>=21.2], col="red", pch=20)
library(caTools)
set.seed(123)
split = sample.split(boston$MEDV, SplitRatio = 0.7)
train = subset(boston, split==TRUE)
test = subset(boston, split==FALSE)
linreg = lm(MEDV ~ LAT + LON + CRIM + ZN + INDUS + CHAS + NOX + RM + AGE + DIS + RAD + TAX + PTRATIO, data=train)
summary(linreg)
summary(linreg)
linreg.pred = predict(linreg, newdata=test)
linreg.sse = sum((linreg.pred - test$MEDV)^2)
linreg.sse
tree = rpart(MEDV ~ LAT + LON + CRIM + ZN + INDUS + CHAS + NOX + RM + AGE + DIS + RAD + TAX + PTRATIO, data=train)
prp(tree)
tree.pred = predict(tree, newdata=test)
tree.sse = sum((tree.pred - test$MEDV)^2)
tree.sse
library(caret)
library(e1071)
cp.grid = expand.grid( .cp = (0:10)*0.001)
tr.control = trainControl(method = "cv", number = 10)
cp.grid = expand.grid( .cp = (0:10)*0.001)
tr = train(MEDV ~ LAT + LON + CRIM + ZN + INDUS + CHAS + NOX + RM + AGE + DIS + RAD + TAX + PTRATIO, data = train, method = "rpart", trControl = tr.control, tuneGrid = cp.grid)
best.tree = tr$finalModel
tr
best.tree = tr$finalModel
prp(best.tree)
best.tree.pred = predict(best.tree, newdata=test)
best.tree.sse = sum((best.tree.pred - test$MEDV)^2)
best.tree.sse
